{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a 3-layer neural network for the task of classifying handwritten digits. The number of classes will be 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processed data available at https://drive.google.com/drive/folders/11gOutVaBOxEROpNgZCmfE-ALrfI5ZeKr?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    # Write your code for the architecture here...\n",
    "    def __init__(self, input_size, hidden_1_size, hidden_2_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_1_size = hidden_1_size\n",
    "        self.hidden_2_size = hidden_2_size\n",
    "        self.num_classes = output_size\n",
    "\n",
    "        # nn.Linear is a feedforward layer, i.e. that it captures weights and bias values\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_1_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_1_size, self.hidden_2_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(self.hidden_2_size, self.num_classes)\n",
    "        \n",
    "        # weight initialisation\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # To use a fully connected network, we need a single vector, not a matrix\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # => logits\n",
    "        \n",
    "        # softmax is not used here as the predefined loss function automatically assigns it\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = []\n",
    "class_labels = []\n",
    "\n",
    "with open('../Lectures/Data/mnist_train_file.txt') as fs:\n",
    "    for line in fs:\n",
    "        data = list(map(int, line.strip().split(','))) \n",
    "        label = data[0]\n",
    "        datapoint = data[1:]\n",
    "        data_points.append(datapoint)\n",
    "        class_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points_test = []\n",
    "class_labels_test = []\n",
    "\n",
    "with open('../Lectures/Data/mnist_test_file.txt') as fs:\n",
    "    for line in fs:\n",
    "        data = list(map(int, line.strip().split(','))) \n",
    "        label = data[0]\n",
    "        datapoint = data[1:]\n",
    "        data_points_test.append(datapoint)\n",
    "        class_labels_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_dataset(Dataset):\n",
    "    def __init__(self, data_points, class_labels):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = data_points\n",
    "        self.labels = class_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        # returns length of the dataset\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # retrieves an item of a given index\n",
    "        d = torch.FloatTensor(self.data[index])\n",
    "        l = torch.LongTensor([self.labels[index]])\n",
    "        return d,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(clf, train_data, batch_size, epochs, learning_rate=0.0001):\n",
    "    optimizer = Adam(clf.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs): # the models are trained over multiple epochs..\n",
    "        train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "        for d, l in train_dataloader:\n",
    "            out = clf(d)\n",
    "            l = l.squeeze(1) # converts the tensor of shape [50 x 1] to [50]\n",
    "            loss = criterion(out, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, test_data):\n",
    "    \n",
    "    test_dataloader = DataLoader(test_data, batch_size=100) # evaluate over a batch of examples which reduces time\n",
    "    clf.eval()\n",
    "    true_class = []\n",
    "    inferred_class = []\n",
    "    for d, l in test_dataloader:\n",
    "        # perform forward pass\n",
    "        out = clf(d)\n",
    "        true_class.extend(l.squeeze(1).numpy().tolist()) # appending the true class values to a global list\n",
    "        # calculate softmax to obtain class probability\n",
    "        inf = F.softmax(out, dim=1)\n",
    "        # use argmax to obtain the inferred classes\n",
    "        inf_class = torch.argmax(inf, dim=1)\n",
    "        inferred_class.extend(inf_class.numpy().tolist())\n",
    "        # compare with the true labels to calculate accuracy\n",
    "        # hint... use two lists to store the inferred classes and true classes for each batch \n",
    "        # ... once you have calulated across all the batches, calulate the accuracy\n",
    "    print(f\"accuracy on test set: {accuracy_score(true_class, inferred_class)}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Putting it altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set: 0.9621\n"
     ]
    }
   ],
   "source": [
    "# sequence of function to be executed is provide below\n",
    "# Fill in the required arguments\n",
    "clf = Classifier(28*28, 2048, 256, 10)\n",
    "train_data = Mnist_dataset(data_points, class_labels)\n",
    "test_data = Mnist_dataset(data_points_test, class_labels_test)\n",
    "batch_size = 50\n",
    "epochs = 5\n",
    "train(clf, train_data, batch_size, epochs)\n",
    "evaluate(clf, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the documentation and try other optimizers like Adam\n",
    "\n",
    "2. Try with different batch sizes. How does it effect performance?\n",
    "\n",
    "3. Try with different hidden layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
